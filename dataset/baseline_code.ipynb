{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khs/miniconda3/envs/dacontv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/khs/miniconda3/envs/dacontv/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'FPS' : 30,\n",
    "    'IMG_SIZE' : 128,\n",
    "    'LEARNING_RATE' : 3e-4,\n",
    "    'BATCH_SIZE' : 4,\n",
    "    'SEED' : 41,\n",
    "    'EPOCHS' : 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train.csv')\n",
    "\n",
    "# 8:2 로 Train / Val 분할\n",
    "train_data, val_data, _, _ = train_test_split(df, df['label'], test_size = 0.2, random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./train/TRAIN_045.mp4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['path'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, video_path_list, label_list, transform = None):\n",
    "        self.video_path_list = video_path_list\n",
    "        self.label_list = label_list\n",
    "        self.tf = transform\n",
    "        self.totensor = transforms.ToTensor()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frames = self.get_video(self.video_path_list[idx])\n",
    "\n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[idx]\n",
    "            return frames, label\n",
    "        else:\n",
    "            return frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_path_list)\n",
    "\n",
    "    def get_video(self, path): # 30 frame 비디오 >> 30장 이미지 얻는 코드\n",
    "        frames = []\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        for _ in range(CFG['FPS']):\n",
    "            _, img = cap.read()\n",
    "            img = cv2.resize(img, (CFG['IMG_SIZE'], CFG['IMG_SIZE']))\n",
    "            img = img / 255.  \n",
    "\n",
    "            frames.append(img)\n",
    "        return torch.FloatTensor(np.array(frames)).permute(3,0,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_data['path'].values, train_data['label'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val_data['path'].values, val_data['label'].values)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.feature_extract = nn.Sequential(\n",
    "            nn.Conv3d(3, 8, (3, 3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.Conv3d(8, 32, (2, 2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.Conv3d(32, 64, (2, 2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.Conv3d(64, 128, (2, 2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.MaxPool3d((1, 7, 7)),\n",
    "        )\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.feature_extract(x)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    best_val_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for videos, label in tqdm(train_loader):\n",
    "            videos = videos.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(videos)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'EPOCH [{epoch}] | TRAIN LOSS [{_train_loss:.5f}] | VAL LOSS [{_val_loss:.5f}] | VAL F1 [{_val_score}]')\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "\n",
    "        if best_val_score < _val_score:\n",
    "            best_val_score = _val_score\n",
    "            best_model = model\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds, trues = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for videos, label in tqdm(iter(val_loader)):\n",
    "            videos = videos.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            logit = model(videos)\n",
    "            loss = criterion(logit, label)\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "            preds += logit.argmax(1).detach().cpu().numpy().tolist() # argmax(1) : axis 1 로 최대 인덱스 반환\n",
    "            trues += label.detach().cpu().numpy().tolist()\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "\n",
    "    _val_score = f1_score(trues, preds, average='macro')\n",
    "    return _val_loss, _val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 12.78it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [1] | TRAIN LOSS [1.49790] | VAL LOSS [1.12766] | VAL F1 [0.5344198168295532]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.36it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [2] | TRAIN LOSS [0.75764] | VAL LOSS [1.04968] | VAL F1 [0.5471941720094016]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.20it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 18.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [3] | TRAIN LOSS [0.49339] | VAL LOSS [1.10295] | VAL F1 [0.5917502169282314]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.48it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 18.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [4] | TRAIN LOSS [0.31543] | VAL LOSS [0.96945] | VAL F1 [0.6473474666917289]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.41it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 18.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [5] | TRAIN LOSS [0.17956] | VAL LOSS [0.78451] | VAL F1 [0.716030767725683]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.24it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [6] | TRAIN LOSS [0.10894] | VAL LOSS [0.88071] | VAL F1 [0.7010657038963153]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.01it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [7] | TRAIN LOSS [0.09766] | VAL LOSS [0.93963] | VAL F1 [0.7059755714006893]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.03it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [8] | TRAIN LOSS [0.07261] | VAL LOSS [0.72318] | VAL F1 [0.7496170030639755]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 12.77it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [9] | TRAIN LOSS [0.09372] | VAL LOSS [1.07188] | VAL F1 [0.6555316599742329]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 12.89it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [10] | TRAIN LOSS [0.10215] | VAL LOSS [1.00302] | VAL F1 [0.6826112901300871]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.07it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [11] | TRAIN LOSS [0.15080] | VAL LOSS [2.20180] | VAL F1 [0.4404647596451311]\n",
      "Epoch    11: reducing learning rate of group 0 to 1.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.06it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [12] | TRAIN LOSS [0.09347] | VAL LOSS [0.74339] | VAL F1 [0.7236286960841486]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 12.97it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [13] | TRAIN LOSS [0.02032] | VAL LOSS [0.74159] | VAL F1 [0.743599770826601]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 12.97it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 16.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [14] | TRAIN LOSS [0.01240] | VAL LOSS [0.82115] | VAL F1 [0.754181608186692]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 12.88it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [15] | TRAIN LOSS [0.00710] | VAL LOSS [0.75682] | VAL F1 [0.7411457536537853]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.34it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [16] | TRAIN LOSS [0.01320] | VAL LOSS [0.74372] | VAL F1 [0.7601594202898551]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.38it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [17] | TRAIN LOSS [0.00530] | VAL LOSS [0.72682] | VAL F1 [0.7616937993996273]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.30it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [18] | TRAIN LOSS [0.00414] | VAL LOSS [0.76614] | VAL F1 [0.7450481905801054]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.33it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [19] | TRAIN LOSS [0.00326] | VAL LOSS [0.73637] | VAL F1 [0.7523944040893193]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.44it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [20] | TRAIN LOSS [0.00180] | VAL LOSS [0.76404] | VAL F1 [0.7696715399435725]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.23it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [21] | TRAIN LOSS [0.00223] | VAL LOSS [0.80096] | VAL F1 [0.726797428483988]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.35it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 18.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [22] | TRAIN LOSS [0.00184] | VAL LOSS [0.74778] | VAL F1 [0.7676417237617807]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.34it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [23] | TRAIN LOSS [0.00173] | VAL LOSS [0.78995] | VAL F1 [0.7608610224242625]\n",
      "Epoch    23: reducing learning rate of group 0 to 7.5000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.48it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 18.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [24] | TRAIN LOSS [0.00186] | VAL LOSS [0.76315] | VAL F1 [0.7698173105720276]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.46it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 18.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [25] | TRAIN LOSS [0.00172] | VAL LOSS [0.80067] | VAL F1 [0.7628117225993869]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.33it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 18.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [26] | TRAIN LOSS [0.00153] | VAL LOSS [0.75904] | VAL F1 [0.7708358142781012]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.29it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 18.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [27] | TRAIN LOSS [0.00130] | VAL LOSS [0.82586] | VAL F1 [0.7866184104825552]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.29it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 18.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [28] | TRAIN LOSS [0.00152] | VAL LOSS [0.80677] | VAL F1 [0.759248597131572]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.41it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 18.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [29] | TRAIN LOSS [0.00105] | VAL LOSS [0.82782] | VAL F1 [0.7595191849443463]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.38it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [30] | TRAIN LOSS [0.00104] | VAL LOSS [0.82598] | VAL F1 [0.7785485329226622]\n",
      "Epoch    30: reducing learning rate of group 0 to 3.7500e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BaseModel()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG['LEARNING_RATE'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2,threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./test.csv')\n",
    "\n",
    "test_dataset = CustomDataset(test['path'].values, None)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for videos in tqdm(iter(test_loader)):\n",
    "            videos = videos.to(device)\n",
    "            \n",
    "            logit = model(videos)\n",
    "\n",
    "            preds += logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:02<00:00, 17.27it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = inference(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 0, 4, 4, 0, 4, 3, 4, 2, 2, 2, 0, 4, 1, 4, 3, 1, 0, 1, 2, 2, 2, 3, 2, 3, 1, 1, 4, 0, 3, 1, 0, 4, 3, 4, 2, 3, 2, 0, 2, 3, 4, 3, 3, 0, 4, 0, 4, 1, 3, 4, 1, 0, 1, 3, 4, 2, 2, 4, 0, 3, 4, 2, 1, 2, 1, 0, 2, 1, 3, 1, 4, 3, 3, 0, 4, 4, 3, 0, 0, 4, 3, 1, 3, 2, 2, 3, 0, 2, 1, 2, 2, 0, 4, 2, 4, 0, 2, 3, 2, 1, 1, 3, 0, 2, 0, 0, 3, 1, 0, 1, 4, 3, 1, 0, 0, 1, 1, 3, 4, 3, 1, 2, 3, 4, 0, 2, 1, 4, 0, 1, 4, 3, 4, 1, 0, 2, 2, 0, 0, 0, 4, 1, 3, 1, 2, 2, 2, 4, 0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['label'] = preds\n",
    "submit.to_csv('base_line_code_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacontv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d557b265a95affbdff337d2f958a092648be297221a6f9dc5505a7fa2c03361"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
