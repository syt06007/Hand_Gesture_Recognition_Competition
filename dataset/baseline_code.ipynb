{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khs/miniconda3/envs/dacontv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/khs/miniconda3/envs/dacontv/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'FPS' : 30,\n",
    "    'IMG_SIZE' : 128,\n",
    "    'LEARNING_RATE' : 3e-4,\n",
    "    'BATCH_SIZE' : 4,\n",
    "    'SEED' : 41,\n",
    "    'EPOCHS' : 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train.csv')\n",
    "\n",
    "# 8:2 로 Train / Val 분할\n",
    "train_data, val_data, _, _ = train_test_split(df, df['label'], test_size = 0.2, random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./train/TRAIN_045.mp4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['path'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, video_path_list, label_list, transform = None):\n",
    "        self.video_path_list = video_path_list\n",
    "        self.label_list = label_list\n",
    "        self.tf = transform\n",
    "        self.totensor = transforms.ToTensor()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frames = self.get_video(self.video_path_list[idx])\n",
    "\n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[idx]\n",
    "            return frames, label\n",
    "        else:\n",
    "            return frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_path_list)\n",
    "\n",
    "    def get_video(self, path): # 30 frame 비디오 >> 30장 이미지 얻는 코드\n",
    "        frames = []\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        for _ in range(CFG['FPS']):\n",
    "            _, img = cap.read()\n",
    "            img = cv2.resize(img, (CFG['IMG_SIZE'], CFG['IMG_SIZE']))\n",
    "            img = img / 255.\n",
    "\n",
    "            frames.append(img)\n",
    "        return torch.FloatTensor(np.array(frames)).permute(3,0,1,2) # 3D convolution (N, C, Frame, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_data['path'].values, train_data['label'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val_data['path'].values, val_data['label'].values)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.bn = nn.BatchNorm3d(out_channels)\n",
    "        self.maxpool = nn.MaxPool3d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.bn(out)\n",
    "        out = self.maxpool(out)\n",
    "        return out\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.feature_extract = nn.Sequential(\n",
    "            ConvBlock(3,8,(3,3,3)),\n",
    "            ConvBlock(8,32,(2,2,2)),\n",
    "            ConvBlock(32,64,(2,2,2)),\n",
    "            \n",
    "            nn.Conv3d(64,128,(2,2,2)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.MaxPool3d((1,7,7)),\n",
    "        )\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.feature_extract(x)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    best_val_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for videos, label in tqdm(train_loader):\n",
    "            videos = videos.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(videos)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'EPOCH [{epoch}] | TRAIN LOSS [{_train_loss:.5f}] | VAL LOSS [{_val_loss:.5f}] | VAL F1 [{_val_score}]')\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "\n",
    "        if best_val_score < _val_score:\n",
    "            best_val_score = _val_score\n",
    "            best_model = model\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds, trues = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for videos, label in tqdm(iter(val_loader)):\n",
    "            videos = videos.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            logit = model(videos)\n",
    "            loss = criterion(logit, label)\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "            preds += logit.argmax(1).detach().cpu().numpy().tolist() # argmax(1) : axis 1 로 최대 인덱스 반환\n",
    "            trues += label.detach().cpu().numpy().tolist()\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "\n",
    "    _val_score = f1_score(trues, preds, average='macro')\n",
    "    return _val_loss, _val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.14it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [1] | TRAIN LOSS [1.36116] | VAL LOSS [0.87905] | VAL F1 [0.664672879041272]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.35it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [2] | TRAIN LOSS [0.64133] | VAL LOSS [0.89428] | VAL F1 [0.684290197868245]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.21it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 18.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [3] | TRAIN LOSS [0.50060] | VAL LOSS [0.63822] | VAL F1 [0.7612261661327616]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.24it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [4] | TRAIN LOSS [0.29733] | VAL LOSS [0.45213] | VAL F1 [0.8144351441976891]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 12.99it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [5] | TRAIN LOSS [0.18507] | VAL LOSS [0.51217] | VAL F1 [0.790667130488559]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 12.67it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 16.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [6] | TRAIN LOSS [0.10598] | VAL LOSS [0.47540] | VAL F1 [0.8514205505341416]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.31it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 18.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [7] | TRAIN LOSS [0.04970] | VAL LOSS [0.48349] | VAL F1 [0.8299033458598842]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.04it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 17.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [8] | TRAIN LOSS [0.04238] | VAL LOSS [0.57771] | VAL F1 [0.7692130877117752]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.33it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 16.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [9] | TRAIN LOSS [0.06883] | VAL LOSS [0.58935] | VAL F1 [0.7863771630668183]\n",
      "Epoch     9: reducing learning rate of group 0 to 1.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.13it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 16.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [10] | TRAIN LOSS [0.02771] | VAL LOSS [0.48755] | VAL F1 [0.8322693922441523]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.08it/s]\n",
      "100%|██████████| 31/31 [00:01<00:00, 18.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [11] | TRAIN LOSS [0.01486] | VAL LOSS [0.47003] | VAL F1 [0.8410824123212752]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [00:09<00:00, 13.22it/s]\n",
      "  0%|          | 0/31 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model = BaseModel()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG['LEARNING_RATE'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2,threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./test.csv')\n",
    "\n",
    "test_dataset = CustomDataset(test['path'].values, None)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for videos in tqdm(iter(test_loader)):\n",
    "            videos = videos.to(device)\n",
    "            \n",
    "            logit = model(videos)\n",
    "\n",
    "            preds += logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = inference(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['label'] = preds\n",
    "submit.to_csv('base_line_code_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacontv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d557b265a95affbdff337d2f958a092648be297221a6f9dc5505a7fa2c03361"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
